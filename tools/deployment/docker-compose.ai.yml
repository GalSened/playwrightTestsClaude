version: '3.8'

services:
  # Main AI Backend Service
  ai-backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: qa-ai-backend
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MONGODB_CONNECTION_STRING=${MONGODB_CONNECTION_STRING}
      - REDIS_URL=${REDIS_URL}
      - AI_MODEL_CACHE_ENABLED=true
      - TENSORFLOW_CPU_THREADS=4
      - TENSORFLOW_MEMORY_LIMIT=2048
    volumes:
      - ai-models:/app/models
      - ai-cache:/app/cache
      - ai-logs:/app/logs
    depends_on:
      - mongodb
      - redis
    networks:
      - ai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/ai/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # MongoDB for AI data storage
  mongodb:
    image: mongo:7.0
    container_name: qa-ai-mongodb
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_PASSWORD}
      - MONGO_INITDB_DATABASE=qa_intelligence
    volumes:
      - mongodb-data:/data/db
      - mongodb-config:/data/configdb
      - ./mongodb-init:/docker-entrypoint-initdb.d
    networks:
      - ai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: qa-ai-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - ai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Nginx reverse proxy and load balancer
  nginx:
    image: nginx:alpine
    container_name: qa-ai-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - nginx-logs:/var/log/nginx
    depends_on:
      - ai-backend
    networks:
      - ai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Prometheus for monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: qa-ai-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    networks:
      - ai-network
    restart: unless-stopped

  # Grafana for visualizations
  grafana:
    image: grafana/grafana:latest
    container_name: qa-ai-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    depends_on:
      - prometheus
    networks:
      - ai-network
    restart: unless-stopped

  # ELK Stack for logging (Elasticsearch)
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: qa-ai-elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - ai-network
    restart: unless-stopped

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: qa-ai-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - ai-network
    restart: unless-stopped

  # Logstash for log processing
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: qa-ai-logstash
    volumes:
      - ./monitoring/logstash:/usr/share/logstash/pipeline
    environment:
      - LS_JAVA_OPTS=-Xmx512m -Xms512m
    depends_on:
      - elasticsearch
    networks:
      - ai-network
    restart: unless-stopped

  # AI Model Trainer (for continuous learning)
  model-trainer:
    build:
      context: ./ml-trainer
      dockerfile: Dockerfile
    container_name: qa-ai-trainer
    environment:
      - TRAINING_SCHEDULE=0 2 * * * # Daily at 2 AM
      - MODEL_STORAGE_PATH=/models
      - TRAINING_DATA_PATH=/training-data
    volumes:
      - ai-models:/models
      - training-data:/training-data
      - ai-logs:/logs
    depends_on:
      - mongodb
      - ai-backend
    networks:
      - ai-network
    restart: unless-stopped

volumes:
  mongodb-data:
    driver: local
  mongodb-config:
    driver: local
  redis-data:
    driver: local
  ai-models:
    driver: local
  ai-cache:
    driver: local
  ai-logs:
    driver: local
  nginx-logs:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  elasticsearch-data:
    driver: local
  training-data:
    driver: local

networks:
  ai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16