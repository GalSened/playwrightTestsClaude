# WeSign Test Orchestrator - User Guide

**Version:** 2.0 â€¢ **Last Updated:** 2025-09-28 â€¢ **Target Audience:** QA Engineers, Test Automation Specialists

> **Quick Start**: Navigate to `http://localhost:3001/wesign` â†’ Click "Orchestrator" tab â†’ Start testing!

## Table of Contents

1. [Getting Started](#getting-started)
2. [User Interface Overview](#user-interface-overview)
3. [Test Execution Workflows](#test-execution-workflows)
4. [Managing Test Suites](#managing-test-suites)
5. [Monitoring Executions](#monitoring-executions)
6. [Working with Reports](#working-with-reports)
7. [Self-Healing Configuration](#self-healing-configuration)
8. [Best Practices](#best-practices)
9. [Troubleshooting Common Issues](#troubleshooting-common-issues)
10. [Advanced Features](#advanced-features)

## Getting Started

### Prerequisites

Before using the WeSign Test Orchestrator, ensure:

1. **Backend Service Running**: `http://localhost:8082` is accessible
2. **Frontend Application**: `http://localhost:3001` is accessible
3. **Test Files Available**: WeSign tests are discovered and loaded
4. **Connection Status**: Green indicator shows "Connected" in the UI

### First Time Setup

1. **Access the Application**
   ```
   Open browser â†’ http://localhost:3001
   Navigate to WeSign â†’ Click "Orchestrator" tab
   ```

2. **Verify System Status**
   - Check the connection indicator (should be green)
   - Review the overview statistics
   - Confirm test suites are loaded

3. **Run Your First Test**
   - Go to "Test Suites" tab
   - Select "Authentication Tests"
   - Click "Execute Suite"
   - Monitor progress in "Executions" tab

## User Interface Overview

### Main Navigation

The WeSign Test Orchestrator is integrated into the QA Intelligence platform:

```
QA Intelligence Dashboard
â”œâ”€ WeSign Testing Hub
â”‚  â”œâ”€ Dashboard (existing functionality)
â”‚  â”œâ”€ Test Management (existing functionality)
â”‚  â””â”€ Orchestrator (NEW - comprehensive testing system)
â”‚     â”œâ”€ Overview
â”‚     â”œâ”€ Test Suites
â”‚     â”œâ”€ Executions
â”‚     â”œâ”€ Reports
â”‚     â””â”€ Settings
```

### Overview Tab

**Purpose**: High-level system monitoring and quick actions

**Key Features**:
- **System Statistics**: Total tests, success rates, active executions
- **Quick Actions**: Execute regression, run smoke tests
- **Recent Activity**: Latest execution results
- **System Health**: Connection status, service health indicators

**What You'll See**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WeSign Test Orchestrator Overview                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“Š Statistics                                               â”‚
â”‚   â€¢ Total Tests: 607    â€¢ Success Rate: 94.2%             â”‚
â”‚   â€¢ Active Executions: 2   â€¢ Tests Today: 234             â”‚
â”‚                                                            â”‚
â”‚ ğŸš€ Quick Actions                                           â”‚
â”‚   [Execute Regression] [Run Smoke Tests] [Auth Tests]      â”‚
â”‚                                                            â”‚
â”‚ ğŸ“ˆ Recent Activity                                         â”‚
â”‚   â€¢ Auth Suite - Completed (98% pass rate)                â”‚
â”‚   â€¢ Signing Tests - Running (Progress: 65%)               â”‚
â”‚   â€¢ Document Tests - Queued                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Test Suites Tab

**Purpose**: Browse, configure, and execute test suites

**Key Features**:
- **Suite Browser**: Visual grid of all available test suites
- **Execution Controls**: Configure and launch test executions
- **Suite Statistics**: Success rates, last execution times
- **Tag Filtering**: Filter suites by category, priority, or custom tags

### Executions Tab

**Purpose**: Monitor active and historical test executions

**Key Features**:
- **Live Progress**: Real-time execution monitoring
- **Execution History**: Browse past executions with filtering
- **Detailed Views**: Drill down into individual test results
- **Cancellation**: Stop running executions when needed

### Reports Tab

**Purpose**: Access and download comprehensive test reports

**Key Features**:
- **Report Gallery**: Visual overview of available reports
- **Download Options**: Multiple formats (HTML, JSON, PDF)
- **Report Previews**: Quick summary views
- **Historical Reports**: Archive of past execution reports

### Settings Tab

**Purpose**: Configure execution parameters and system settings

**Key Features**:
- **Execution Settings**: Default workers, timeouts, retries
- **Self-Healing Configuration**: Enable/disable healing strategies
- **Notification Settings**: Configure alerts and notifications
- **Environment Management**: Switch between test environments

## Test Execution Workflows

### Workflow 1: Execute Individual Test

**Use Case**: Debug a specific failing test or validate a single scenario

**Steps**:

1. **Navigate to Test Suites**
   ```
   WeSign â†’ Orchestrator â†’ Test Suites
   ```

2. **Find Your Test**
   - Use the search bar: "test_login_success"
   - Or browse by suite: "Authentication Tests"
   - Click on the test name to view details

3. **Configure Execution**
   ```
   Execution Type: Individual
   Self-Healing: âœ“ Enabled
   Environment: Staging
   Report Formats: Comprehensive + Allure
   ```

4. **Start Execution**
   - Click "Execute Test"
   - Note the execution ID for tracking
   - Switch to "Executions" tab to monitor

5. **Monitor Progress**
   - Watch real-time progress updates
   - View live logs and screenshots
   - Check self-healing attempts if any failures occur

6. **Review Results**
   - Access generated reports
   - Download artifacts (screenshots, logs)
   - Analyze failure details if test failed

**Expected Timeline**: 1-5 minutes for most individual tests

### Workflow 2: Execute Test Suite

**Use Case**: Run all tests in a functional area (e.g., authentication, signing)

**Steps**:

1. **Select Suite**
   ```
   Test Suites â†’ Authentication Tests
   Click "Execute Suite" button
   ```

2. **Configure Suite Execution**
   ```
   Parallel Execution: âœ“ Enabled
   Max Workers: 3
   Self-Healing: âœ“ Enabled
   Environment: Staging
   Include Tags: [critical, smoke]
   Exclude Tags: [flaky]
   ```

3. **Review Test Selection**
   - Confirm test count (e.g., 45 tests)
   - Review estimated duration (e.g., 12 minutes)
   - Check included/excluded tests

4. **Start Suite Execution**
   - Click "Start Execution"
   - Execution begins immediately
   - Switch to monitoring view

5. **Monitor Suite Progress**
   ```
   Progress: 45/45 tests (65% complete)
   Passed: 28 tests
   Failed: 2 tests (with healing attempts)
   Running: 3 tests
   Queue: 12 tests
   ```

6. **Handle Failures**
   - Review failed tests
   - Check self-healing attempts
   - Decision: Continue, retry, or investigate

7. **Review Suite Results**
   - Download comprehensive report
   - Analyze failure patterns
   - Share results with team

**Expected Timeline**: 10-30 minutes depending on suite size

### Workflow 3: Execute Regression Testing

**Use Case**: Full system validation before releases or major changes

**Steps**:

1. **Initiate Regression**
   ```
   Overview â†’ Quick Actions â†’ "Execute Regression"
   OR
   Test Suites â†’ "Execute All Suites"
   ```

2. **Configure Regression**
   ```
   Execution Type: Regression
   Parallel Workers: 5
   Environment: Staging
   Include Categories: All
   Exclude Categories: [Performance] (optional)
   Self-Healing: âœ“ Enabled
   Report Formats: Comprehensive + Allure + Newman
   ```

3. **Review Scope**
   ```
   Total Tests: 607
   Estimated Duration: 45-60 minutes
   Resource Requirements: 5 parallel workers
   ```

4. **Start Regression**
   - Confirm configuration
   - Click "Start Regression"
   - Monitor system resource usage

5. **Monitor Large-Scale Execution**
   ```
   Overall Progress: 45%
   Category Progress:
   â”œâ”€ Authentication: âœ“ Complete (98% pass)
   â”œâ”€ Signing: ğŸ”„ Running (65% complete)
   â”œâ”€ Documents: â³ Queued
   â””â”€ Integration: â³ Queued
   ```

6. **Handle Mid-Execution Issues**
   - **High Failure Rate**: Consider pausing to investigate
   - **Resource Issues**: Reduce parallel workers
   - **Environment Issues**: Switch environments if needed

7. **Regression Completion**
   - Download comprehensive regression report
   - Analyze category-wise results
   - Generate executive summary
   - Share with stakeholders

**Expected Timeline**: 45-90 minutes for full regression

### Workflow 4: API Test Execution

**Use Case**: Validate backend services and API endpoints

**Steps**:

1. **Access API Test Suites**
   ```
   Test Suites â†’ Filter by Type: "API"
   Available Suites:
   â”œâ”€ Auth API Tests
   â”œâ”€ Document API Tests
   â”œâ”€ Signing API Tests
   â””â”€ Integration API Tests
   ```

2. **Configure API Execution**
   ```
   Execution Type: Suite (API)
   Newman Integration: âœ“ Enabled
   Postman Collections: Auto-detected
   Environment Variables: Staging
   Parallel Requests: âœ“ Enabled
   ```

3. **Monitor API Testing**
   - Watch HTTP request/response logs
   - Monitor response times
   - Track assertion results
   - Check schema validations

4. **Review API Results**
   - Download Newman reports
   - Analyze response time trends
   - Check endpoint coverage
   - Validate data integrity

**Expected Timeline**: 5-15 minutes for API suites

## Managing Test Suites

### Understanding Test Organization

Tests are organized in a hierarchical structure:

```
WeSign Tests (607 total)
â”œâ”€ Authentication Tests (75 tests)
â”‚  â”œâ”€ Login/Logout Scenarios
â”‚  â”œâ”€ Token Management
â”‚  â”œâ”€ Password Recovery
â”‚  â””â”€ Multi-factor Authentication
â”œâ”€ Signing Tests (120 tests)
â”‚  â”œâ”€ Document Signing Workflows
â”‚  â”œâ”€ Signature Validation
â”‚  â”œâ”€ Bulk Signing Operations
â”‚  â””â”€ Signing History
â”œâ”€ Document Management (95 tests)
â”‚  â”œâ”€ Document Upload/Download
â”‚  â”œâ”€ Document Processing
â”‚  â”œâ”€ Version Control
â”‚  â””â”€ Access Control
â””â”€ [Additional Categories...]
```

### Suite Management Operations

#### Creating Custom Test Runs

1. **Select Tests Manually**
   ```
   Test Suites â†’ "Create Custom Run"
   Search/Filter Tests:
   - By Category: Authentication
   - By Tag: [critical, smoke]
   - By Status: Recently Failed
   - By Duration: < 30 seconds
   ```

2. **Build Custom Suite**
   ```
   Selected Tests: 25 tests
   Estimated Duration: 8 minutes
   Categories Covered: Auth (15), Signing (10)
   ```

3. **Save for Reuse**
   ```
   Suite Name: "Smoke Test Suite"
   Description: "Critical path validation"
   Tags: [smoke, critical, daily]
   ```

#### Tagging and Categorization

**Available Tags**:
- **Priority**: `critical`, `high`, `medium`, `low`
- **Type**: `smoke`, `regression`, `integration`, `performance`
- **Stability**: `stable`, `flaky`, `new`
- **Environment**: `dev`, `staging`, `production`

**Usage Examples**:
```bash
# Execute only critical tests
Filter: tags=critical

# Execute stable regression tests
Filter: tags=regression,stable

# Execute new tests for validation
Filter: tags=new
```

## Monitoring Executions

### Real-time Monitoring Features

#### Live Progress Dashboard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execution: exec_20250928_103045_abc123                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Status: Running          Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–’â–’ 65%          â”‚
â”‚ Started: 10:30 AM        ETA: 10:52 AM                     â”‚
â”‚                                                            â”‚
â”‚ Tests: 28/45 Complete                                      â”‚
â”‚ âœ… Passed: 25           âŒ Failed: 2        â¸ï¸ Skipped: 1    â”‚
â”‚ ğŸ”„ Running: Document Upload Flow                          â”‚
â”‚                                                            â”‚
â”‚ Self-Healing: 3 attempts (2 successful)                   â”‚
â”‚ Workers: 3/3 active                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Live Log Streaming

```
[10:35:22] Starting test_document_upload...
[10:35:23] âœ“ Navigation to upload page successful
[10:35:24] âœ“ File selection completed
[10:35:25] âš ï¸ Upload button not clickable - initiating healing
[10:35:26] ğŸ”§ Healing: Trying alternative selector
[10:35:27] âœ“ Healing successful - upload proceeding
[10:35:30] âœ“ Document uploaded successfully
[10:35:31] âœ… test_document_upload PASSED (9.2s)
```

#### Execution Controls

**Available Actions During Execution**:
- **Pause Execution**: Temporarily halt new test starts
- **Resume Execution**: Continue paused execution
- **Cancel Execution**: Stop all running tests
- **Adjust Workers**: Increase/decrease parallel workers
- **View Logs**: Access real-time execution logs

### Historical Execution Analysis

#### Execution History View

```
Recent Executions (Last 30 days)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Date/Time           Type        Status      Duration  Pass% â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2025-09-28 10:30   Regression   Completed   52m       94%   â”‚
â”‚ 2025-09-28 08:15   Auth Suite   Completed   12m       98%   â”‚
â”‚ 2025-09-27 16:45   Signing      Failed      8m        67%   â”‚
â”‚ 2025-09-27 14:20   Documents    Completed   15m       91%   â”‚
â”‚ 2025-09-27 10:00   Regression   Completed   48m       95%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Filtering and Search

```
Filter Options:
- Status: [All, Completed, Failed, Running, Cancelled]
- Type: [All, Individual, Suite, Regression]
- Date Range: [Last 7 days, Last 30 days, Custom]
- Suite: [All, Authentication, Signing, Documents, ...]
- Pass Rate: [All, >95%, 90-95%, <90%]
```

#### Trend Analysis

**Success Rate Trends**:
- Weekly pass rate: 94.2% (up from 92.1%)
- Most reliable suite: Authentication (98.7% pass rate)
- Most improved: Signing Tests (8% improvement this month)

**Performance Trends**:
- Average execution time: 14.2 minutes (down from 16.8 minutes)
- Self-healing success rate: 87.5% (up from 82.3%)

## Working with Reports

### Report Types Overview

#### Comprehensive Reports

**Content**: Unified view of all test results
**Format**: Interactive HTML with embedded charts
**Best For**: Stakeholder presentations, executive summaries

**Sections**:
1. **Executive Summary**: High-level metrics and status
2. **Test Results**: Detailed pass/fail breakdown
3. **Performance Metrics**: Execution times, resource usage
4. **Failure Analysis**: Categorized failure reasons
5. **Self-Healing Summary**: Healing attempts and success rates
6. **Environment Details**: Configuration and setup information

#### Allure Reports

**Content**: Rich UI test reports with visual elements
**Format**: Interactive HTML with drill-down capabilities
**Best For**: Test engineers, detailed debugging

**Features**:
- Step-by-step execution traces
- Screenshots at each step
- Browser console logs
- Network request details
- Performance timing information

#### Newman Reports

**Content**: API test execution details
**Format**: JSON and HTML formats
**Best For**: API testing validation, integration verification

**Features**:
- HTTP request/response details
- Response time analysis
- Status code validation
- JSON schema validation results
- Collection run summaries

### Accessing Reports

#### From the UI

1. **Navigate to Reports Tab**
   ```
   Orchestrator â†’ Reports
   ```

2. **Browse Available Reports**
   ```
   Recent Reports:
   â”œâ”€ Regression_20250928_103045 (Comprehensive, Allure)
   â”œâ”€ AuthSuite_20250928_081500 (Comprehensive, Newman)
   â””â”€ SigningTests_20250927_164500 (Comprehensive, Allure)
   ```

3. **Preview and Download**
   - Click report name for preview
   - Use download buttons for offline access
   - Share report URLs with team members

#### Programmatic Access

```bash
# Download comprehensive report
curl -O http://localhost:8082/api/wesign-tests/executions/exec_123/reports/comprehensive

# Download Allure report
curl -O http://localhost:8082/api/wesign-tests/executions/exec_123/reports/allure

# Download Newman report
curl -O http://localhost:8082/api/wesign-tests/executions/exec_123/reports/newman
```

### Report Interpretation

#### Understanding Comprehensive Reports

**Executive Summary Section**:
```
Test Execution Summary
======================
Execution ID: exec_20250928_103045_abc123
Execution Type: Regression
Duration: 52 minutes 38 seconds
Total Tests: 607
âœ… Passed: 571 (94.1%)
âŒ Failed: 28 (4.6%)
â¸ï¸ Skipped: 8 (1.3%)

Self-Healing Summary
===================
Total Healing Attempts: 45
Successful Heals: 39 (86.7%)
Tests Saved by Healing: 39
Time Saved: 23 minutes
```

**Category Breakdown**:
```
Results by Category
==================
Authentication:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 98.7% (74/75)
Documents:        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 94.7% (90/95)
Signing:          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–’â–’â–’â–’ 91.7% (110/120)
Templates:        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 96.2% (50/52)
Users:            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%  (35/35)
Integration:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–’â–’â–’â–’ 88.9% (80/90)
Performance:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 95.0% (95/100)
Security:         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–’â–’â–’â–’ 90.0% (36/40)
```

#### Failure Analysis

**Common Failure Patterns**:
1. **Element Not Found (35%)**: UI elements changed or timing issues
2. **Network Timeout (25%)**: API endpoints slow or unavailable
3. **Authentication Issues (20%)**: Token expiration or credential problems
4. **Data Validation (15%)**: Unexpected data formats or values
5. **Environment Issues (5%)**: Infrastructure or configuration problems

**Healing Success by Pattern**:
- Element Not Found: 92% healing success
- Network Timeout: 78% healing success
- Authentication Issues: 95% healing success
- Data Validation: 45% healing success

## Self-Healing Configuration

### Understanding Self-Healing

Self-healing automatically detects common failure patterns and attempts to recover without human intervention.

#### Healing Strategies

**1. Authentication Strategy**
- **Triggers**: Token expiration, session timeout, login failures
- **Actions**: Refresh tokens, re-authenticate, try alternative credentials
- **Success Rate**: 95%

**2. Element Interaction Strategy**
- **Triggers**: Element not found, not clickable, not visible
- **Actions**: Wait longer, try alternative selectors, adjust viewport
- **Success Rate**: 89%

**3. Network Strategy**
- **Triggers**: Timeout, connection refused, slow responses
- **Actions**: Retry with backoff, try alternative endpoints, adjust timeouts
- **Success Rate**: 82%

**4. Data Dependent Strategy**
- **Triggers**: Invalid test data, data conflicts, missing dependencies
- **Actions**: Generate fresh data, reset state, cleanup artifacts
- **Success Rate**: 67%

### Configuring Self-Healing

#### Global Settings

Access via `Orchestrator â†’ Settings â†’ Self-Healing`:

```
Self-Healing Configuration
=========================
âœ“ Enable Self-Healing
  Max Attempts per Test: 3
  Progressive Delays: 1s, 2s, 5s

Strategy Selection:
âœ“ Authentication Healing
âœ“ Element Interaction Healing
âœ“ Network Healing
âœ“ Data Dependent Healing

Learning Mode:
âœ“ Enable Learning from Failures
  Update Strategy Success Rates: âœ“
  Suggest New Patterns: âœ“
```

#### Per-Suite Configuration

```javascript
// Suite-specific healing configuration
{
  "suiteId": "auth-suite",
  "healing": {
    "enabled": true,
    "maxAttempts": 2,
    "strategies": ["authentication", "elementInteraction"],
    "customPatterns": [
      {
        "pattern": "Login button not clickable",
        "strategy": "waitAndRetry",
        "maxWait": 10000
      }
    ]
  }
}
```

#### Test-Level Configuration

```python
# Individual test healing configuration
@pytest.mark.healing(
    enabled=True,
    max_attempts=3,
    strategies=["authentication", "network"],
    custom_logic="retry_with_fresh_token"
)
def test_document_upload_with_auth():
    # Test implementation
    pass
```

### Monitoring Healing Effectiveness

#### Healing Dashboard

```
Self-Healing Analytics (Last 30 Days)
====================================
Total Healing Attempts: 1,247
Successful Heals: 1,089 (87.3%)
Tests Saved: 1,089
Execution Time Saved: 18.2 hours

Top Healing Strategies:
1. Authentication: 456 attempts (95.2% success)
2. Element Interaction: 389 attempts (89.7% success)
3. Network: 234 attempts (82.3% success)
4. Data Dependent: 168 attempts (67.9% success)

Failure Pattern Trends:
- Element selectors: 15% decrease (improved stability)
- Network timeouts: 8% increase (investigate infrastructure)
- Auth token issues: 25% decrease (improved token management)
```

#### Learning Insights

```
Pattern Learning (Last 7 Days)
==============================
New Patterns Discovered: 3
1. "Document preview loading timeout" â†’ Network strategy (85% success)
2. "Signature pad not responding" â†’ Element interaction (92% success)
3. "API rate limit exceeded" â†’ Progressive backoff (78% success)

Strategy Optimizations:
- Increased default wait time for file uploads (3s â†’ 5s)
- Added viewport adjustment for responsive elements
- Updated token refresh timing (58min â†’ 55min)
```

## Best Practices

### Test Execution Best Practices

#### 1. Test Selection Strategy

**For Development Workflow**:
```
Daily: Run smoke tests (15-20 critical tests, 5-10 minutes)
Feature: Run related test suite (category-specific, 15-30 minutes)
Pre-commit: Run affected tests (changed functionality, 10-20 minutes)
```

**For Release Workflow**:
```
Weekly: Full regression (all tests, 45-90 minutes)
Release Candidate: Regression + performance tests
Production Deploy: Smoke tests + monitoring tests
```

#### 2. Parallel Execution Guidelines

**Resource-Based Sizing**:
- **Development Machine**: 2-3 workers
- **CI/CD Pipeline**: 5-8 workers
- **Dedicated Test Server**: 8-12 workers

**Test-Type Considerations**:
- **UI Tests**: Limit to 3-5 parallel (browser resource intensive)
- **API Tests**: Higher parallelism possible (10+ workers)
- **Integration Tests**: Consider dependencies, limit parallelism

#### 3. Environment Management

**Environment Selection**:
```
Development: Individual tests, debugging, new features
Staging: Suite testing, integration validation
Production: Smoke tests only, post-deployment validation
```

**Environment Configuration**:
- Use environment-specific test data
- Configure appropriate timeouts per environment
- Set up proper authentication per environment

### Self-Healing Best Practices

#### 1. Strategy Selection

**Enable for Flaky Tests**:
- Tests with occasional element timing issues
- Tests dependent on external services
- Tests with authentication dependencies

**Disable for Strict Validation**:
- Security tests requiring exact behavior
- Performance tests with strict timing requirements
- Tests validating error conditions

#### 2. Monitoring and Maintenance

**Regular Review**:
- Weekly review of healing success rates
- Monthly analysis of new failure patterns
- Quarterly optimization of healing strategies

**Performance Impact**:
- Monitor overall execution time impact
- Balance healing attempts vs. fast failure
- Consider test stability improvements over healing

### Reporting Best Practices

#### 1. Report Selection by Audience

**For Executives**:
- Comprehensive reports with executive summary
- Focus on pass rates, trends, and business impact
- Include self-healing benefits and time savings

**For Developers**:
- Allure reports with detailed failure traces
- Include screenshots, logs, and debugging information
- Provide links to specific failing tests

**For QA Team**:
- Comprehensive reports with failure analysis
- Include healing attempts and strategy effectiveness
- Provide recommendations for test improvements

#### 2. Report Archival and Organization

**Retention Policy**:
```
Daily Runs: Keep for 30 days
Weekly Runs: Keep for 6 months
Release Runs: Keep for 2 years
Critical Issues: Keep indefinitely
```

**Organization Structure**:
```
reports/
â”œâ”€ 2025/
â”‚  â”œâ”€ 09/
â”‚  â”‚  â”œâ”€ daily/
â”‚  â”‚  â”œâ”€ weekly/
â”‚  â”‚  â””â”€ releases/
â”‚  â””â”€ 10/
â””â”€ archives/
```

## Troubleshooting Common Issues

### Connection Issues

#### Problem: WebSocket Connection Failed

**Symptoms**:
- "Disconnected" status in UI
- No real-time updates
- Stale execution progress

**Solutions**:
1. **Check Backend Service**
   ```bash
   curl http://localhost:8082/health
   ```

2. **Verify WebSocket Endpoint**
   ```bash
   # In browser console
   new WebSocket('ws://localhost:8082/ws/wesign')
   ```

3. **Restart Services**
   ```bash
   # Backend
   cd backend && npm run dev

   # Frontend
   cd apps/frontend/dashboard && npm run dev
   ```

#### Problem: Test Discovery Failed

**Symptoms**:
- Empty test suites
- "No tests found" message
- Missing test categories

**Solutions**:
1. **Verify Test Path**
   ```bash
   ls "C:/Users/gals/seleniumpythontests-1/playwright_tests"
   ```

2. **Check Permissions**
   ```bash
   # Windows
   icacls "C:/Users/gals/seleniumpythontests-1/playwright_tests" /T
   ```

3. **Manual Test Discovery**
   ```bash
   curl http://localhost:8082/api/wesign-tests/suites
   ```

### Execution Issues

#### Problem: Tests Hanging or Timing Out

**Symptoms**:
- Executions stuck in "Running" status
- Tests exceed expected duration
- No progress updates

**Solutions**:
1. **Check Resource Usage**
   - Monitor CPU and memory usage
   - Reduce parallel workers if needed
   - Check for browser process accumulation

2. **Adjust Timeouts**
   ```json
   {
     "timeout": 60000,  // Increase from 30000
     "retries": 1,      // Reduce retries
     "headless": true   // Ensure headless mode
   }
   ```

3. **Enable Debug Logging**
   ```bash
   DEBUG=wesign:* npm run dev
   ```

#### Problem: High Failure Rate

**Symptoms**:
- Multiple tests failing simultaneously
- Previously passing tests now failing
- Environment-related failures

**Solutions**:
1. **Check Environment Health**
   - Verify WeSign application accessibility
   - Test authentication endpoints manually
   - Check network connectivity

2. **Review Recent Changes**
   - Application updates affecting UI elements
   - API changes affecting endpoints
   - Infrastructure changes

3. **Analyze Failure Patterns**
   ```bash
   # Check logs for common error patterns
   grep -i "error\|timeout\|failed" logs/wesign-orchestrator.log
   ```

### Self-Healing Issues

#### Problem: Healing Not Working

**Symptoms**:
- No healing attempts shown
- All healing attempts failing
- Healing not triggering for obvious patterns

**Solutions**:
1. **Verify Healing Configuration**
   ```json
   {
     "selfHealingEnabled": true,
     "maxAttempts": 3,
     "strategies": ["authentication", "elementInteraction"]
   }
   ```

2. **Check Healing Logs**
   ```bash
   grep "healing" logs/wesign-orchestrator.log
   ```

3. **Manual Pattern Testing**
   - Test specific failure scenarios
   - Verify strategy applicability
   - Check healing logic implementation

### Report Generation Issues

#### Problem: Reports Not Generating

**Symptoms**:
- "Report generation failed" errors
- Missing report files
- Incomplete report content

**Solutions**:
1. **Check Report Dependencies**
   ```bash
   # Verify Allure installation
   allure --version

   # Verify Newman installation
   newman --version
   ```

2. **Verify File Permissions**
   ```bash
   mkdir -p ./reports
   chmod 755 ./reports
   ```

3. **Manual Report Generation**
   ```bash
   # Test Allure generation
   allure generate ./allure-results --output ./test-report

   # Test Newman report
   newman run collection.json --reporters json,html
   ```

## Advanced Features

### Custom Test Configuration

#### Environment-Specific Configuration

Create configuration files for different environments:

```json
// config/staging.json
{
  "environment": "staging",
  "baseUrl": "https://staging.wesign.com",
  "timeout": 30000,
  "retries": 2,
  "parallelWorkers": 3,
  "selfHealing": {
    "enabled": true,
    "maxAttempts": 3,
    "strategies": ["authentication", "elementInteraction", "network"]
  },
  "tags": {
    "include": ["smoke", "regression"],
    "exclude": ["performance", "load"]
  }
}
```

#### Custom Test Tags

Add custom tags to organize and filter tests:

```python
@pytest.mark.wesign_tags(["critical", "auth", "smoke"])
@pytest.mark.environment(["staging", "production"])
@pytest.mark.priority("high")
def test_login_with_valid_credentials():
    pass
```

### API Integration

#### Webhook Notifications

Configure webhooks for execution events:

```json
{
  "webhooks": {
    "executionCompleted": "https://slack.company.com/webhook/executions",
    "testFailed": "https://pagerduty.company.com/webhook/alerts",
    "healingSuccess": "https://metrics.company.com/webhook/healing"
  }
}
```

#### External System Integration

Integrate with CI/CD pipelines:

```bash
# Jenkins Pipeline
pipeline {
    stage('WeSign Tests') {
        steps {
            script {
                def executionId = sh(
                    script: "curl -X POST http://localhost:8082/api/wesign-tests/execute/regression",
                    returnStdout: true
                ).trim()

                // Monitor execution
                waitUntil {
                    def status = sh(
                        script: "curl http://localhost:8082/api/wesign-tests/executions/${executionId}",
                        returnStdout: true
                    )
                    return status.contains('"status":"completed"')
                }
            }
        }
    }
}
```

### Performance Optimization

#### Test Execution Optimization

1. **Smart Test Ordering**
   - Run faster tests first
   - Group tests by resource requirements
   - Balance parallel worker loads

2. **Resource Management**
   - Monitor browser memory usage
   - Implement cleanup between tests
   - Use shared browser contexts when possible

3. **Data Management**
   - Use test data factories
   - Implement data cleanup strategies
   - Share immutable test data across tests

#### Reporting Optimization

1. **Selective Report Generation**
   ```json
   {
     "reportFormats": ["comprehensive"],  // Skip heavy formats for dev runs
     "includeArtifacts": false,          // Skip screenshots for fast feedback
     "summaryOnly": true                 // Generate summary reports only
   }
   ```

2. **Parallel Report Generation**
   - Generate different report formats in parallel
   - Use background processing for large reports
   - Cache common report elements

### Monitoring and Alerting

#### Custom Metrics

Track custom metrics for your testing:

```javascript
// Custom metric tracking
const metrics = {
  testExecution: {
    duration: execution.duration,
    passRate: execution.passedTests / execution.totalTests,
    healingEffectiveness: execution.healing.successfulHeals / execution.healing.attemptsMade
  },
  systemHealth: {
    resourceUsage: getResourceUsage(),
    responseTime: getAverageResponseTime(),
    errorRate: getErrorRate()
  }
};
```

#### Alert Configuration

Set up alerts for critical events:

```json
{
  "alerts": {
    "passRateBelow80": {
      "enabled": true,
      "threshold": 80,
      "notification": ["email", "slack"]
    },
    "executionDurationExceeded": {
      "enabled": true,
      "threshold": 3600,  // 1 hour
      "notification": ["email"]
    },
    "healingFailureSpike": {
      "enabled": true,
      "threshold": 50,  // 50% failure rate
      "notification": ["slack", "pagerduty"]
    }
  }
}
```

---

## Support and Resources

### Getting Help

1. **Documentation**: Reference the [API Documentation](./API_DOCUMENTATION.md) for technical details
2. **System Health**: Monitor at `http://localhost:8082/health`
3. **Logs**: Check backend logs for detailed execution information
4. **Community**: Join the QA Intelligence platform discussion forums

### Training Resources

1. **Video Tutorials**: Available in the platform help section
2. **Best Practices Guide**: This document serves as the comprehensive guide
3. **API Examples**: See the API documentation for integration examples

### Feedback and Improvement

We continuously improve the WeSign Test Orchestrator based on user feedback:

1. **Feature Requests**: Submit via the platform feedback form
2. **Bug Reports**: Include execution IDs and detailed steps to reproduce
3. **Performance Issues**: Provide system specifications and usage patterns

---

*WeSign Test Orchestrator - Empowering Quality Through Intelligent Testing*